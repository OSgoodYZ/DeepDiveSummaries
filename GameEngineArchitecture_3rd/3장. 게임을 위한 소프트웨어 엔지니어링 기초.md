## 3장: 게임을 위한 소프트웨어 엔지니어링 기초
수에 대한 기초와 표현법에 대해 살펴보고, 널리 쓰이는 컴퓨터 및 CPU 구성 요소와 구조, 기계어와 어셈블리 언어, C++ 프로그래밍 언어에 대해서 알아본다.

### 3.1 C++ 개념과 올바른 사용법

#### 3.1.1 객체지향 프로그래밍에 대한 간단한 개념

- 클래스와 객체
- 캡슐화
- 상속
- 다형성
- 합성과 집한
- 디자인 패턴

#### 3.1.2 C++ 표준화화
해당 장에서는 C++의 역사에 따라서 중요한 변경점을 설명한다. 자세한 내용은 직접 읽어보는 것이 좋다(내 의견).

##### 3.1.2.2 언어의 어떤 기능을 술 것인가?
C++의 추가된 기능을 봤을 때, 당연히 이 모든 것을 엔진이나 게임에 쓰고 싶을 것이다. 그러나 당장 그 기술들을 쓸 필요는 없다.
너티 독에서는 언어의 새 기능을 도입할 때 보수적으로 접근했다.

#### 3.1.3 코딩 규칙: 필요한 이유와 적용 정도
필요성은 다음과 같다.
1. 특정 규칙을 준수하면 코드를 읽고 이해하기 쉬워지며 유지 비용도 적게 든다.
2. 터무니 없는 실수를 줄일 수 있다.

글쓴이가 생각하는 중요한 규칙은 아래와 같다.
- 인터페이스를 중시할 것
- 이름을 잘 지을 것
- 전역 네임스페이스를 깔금하게 유지할 것
- 널리 알려진 C++ 사용법을 따를 것
- 코딩 규칙은 일관돼야 할 것
- 오류를 스스로 드러내는 코드를 작성할 것

### 3.2 에러 감지와 처리

#### 3.2.3 에러 감지와 에러 처리 구현
프로그래밍에서 에러 감지와 처리 방법을 살펴본다.

##### 3.2.3.1 에러 리턴 코드
- 함수에서 에러를 감지하면 특정 에러 코드를 반환하는 방식.
- 불리언 값 반환: 성공(true) 또는 실패(false)로 표현.
- 음의 값 반환: 정상적인 값이 양수일 때, 음수를 에러 코드로 활용.
- 열거형 반환: 여러 개의 에러 상태를 정의하여 보다 정확한 원인 제공.
   - 예) enum Error { kSuccess, kAssetNotFound, kInvalidRange, ... }
- 리턴된 에러 코드를 적절히 처리해야 하며, 그대로 호출한 함수에 전달할 수도 있다.
##### 3.2.3.2 예외 처리
- 리턴 코드 방식의 한계: 에러를 처음 감지한 함수에서 처리하기 어려울 수 있음.
  - 예) 게임 루프에서만 에러 처리가 가능한 경우, 여러 함수가 중간에 개입하면 전달이 복잡해짐.
- 예외 처리(exception handling):
  - C++에서 제공하는 기능으로, 예외를 던지고(throw) try-catch 블록에서 처리.
  - 예외 객체를 활용하여 오류 정보를 포함한 상태 전달 가능.
  - try 블록에서 예외가 발생하면, 적절한 catch 블록이 실행되며 자원 해제 등이 자동 수행됨.

- 예외 처리의 장점과 단점  
✅ 장점:

  - 코드가 깔끔하게 분리됨.
  - 특정 영역에서만 예외 처리를 사용 가능.
  - 예외가 발생해도 함수들이 스택을 따라 정리됨(stack unwinding).
  
  ❌ 단점:

  - 성능 저하 가능 (스택 프레임 관리 비용 증가).
  - 전체 프로그램에서 예외를 다룰 방법이 명확해야 함.
  - 예외가 던져질 때 어떤 스택이 호출될지 예측 어려움.
  - 일부 라이브러리는 예외 처리를 사용하지 않음 (예: NASA, JPL, 게임 엔진 등).
- 게임 엔진에서 예외 처리의 논쟁  
많은 게임 엔진에서는 예외 처리를 사용하지 않음.
마이크 액튼(Mike Acton)과 Insomniac Games의 엔진 디렉터들이 예외 사용을 피할 것을 권장.
임베디드 소프트웨어(NASA 등)에서도 미션 크리티컬한 환경에서는 예외 사용을 지양.
예외 처리를 쓰면 유지보수성이 증가하지만, 성능과 예측 가능성이 저하될 수 있음.

- RAII(Resource Acquisition Is Initialization)와 예외 처리
RAII 패턴: 객체 생성 시 자원을 확보하고, 소멸자에서 자원을 정리하는 방식.
예외와 함께 사용하면 자원 관리가 쉬워짐.
하지만 예외 없이도 활용 가능:
객체를 생성한 후 상태를 검사하여 실패 여부를 확인하는 방식으로도 대체 가능.
예외를 던지지 않아도 RAII의 장점을 살릴 수 있음.

##### 3.2.3.3 어서션

assertion은 어 떤 코드의 논리적 기반이 되는 어쩐 전제를 실수로 침범하는 일을 방지한다. 왜냐하면 그 전제를 침법하는 순간 바로 터지는 지뢰와 같기 때문이다.

### 3.3 데이터, 코드, 메모리 레이아웃
#### 3.3.1 수 표현
컴퓨터 공학에서 대부분의 마이크로프로세서는 음의 정수를 표현하기 위해 '2의 보수' 방법을 사용한다.

##### 3.3.1.3 고정소수점 표현법

정수부분을 나타내는 비트와 소수부분을 나타낼 비트를 정해두고 사용한다.

##### 3.3.1.4 부동소수점 표현법

부동소수는 정수와 소수를 합친 가수와 가수 안에서 소수점이 어디 위치할지 나타내는 지수 그리고 부호 비트 이렇게 세 부분으로 이뤄진다.
부동소수의 정확도는 절대값이 작을수록 높아진다.
- ULP: 2개의 부동소수가 있는데, 가수의 가장 낮은 유효 숫자의 값을 제외하고는 모두 같다고 하자. 이 때 두 값은 1ULP(Unit in the Last Place)의 차가 있다고 말한다.


##### 3.3.2.1 멀티바이트 데이터와 엔디언

- 리틀 엔디언: LSB(Least Significant Byte)가 MSB(Most Significant Byte)보다 낮은 메모리 주소에 저장되는 방법이다.
- 빅 엔디언: MSB(Most Significant Byte)가 LSB(Least Significant Byte)보다 낮은 메모리 주소에 저장되는 방법이다.

#### 3.3.3 킬로바이트 vs 키비바이트

- 킬로바이트(kB) : 기존 10진법 단위로 되어있는 단위 표시계, 1000바이트
- 키비바이트(KB) : 2진법 단위로 되어있는 단위 표시계, 1024바이트

#### 3.3.4 선언, 정의 연결성

- 선언: 데이터 객체나 함수의 형태를 나타낸다. 컴퍼일러에 `이름`과 데이터 타입 또는 함수의 서명을 알려준다.
- 정의: 프로그램 안에 고유한 저장 공간을 나타낸다. 이 저장 공간 안에는 변수, 구조체 및 클래스의 인스턴스, 함수의 기계어 등이 들어갈 수 있다.

##### 3.3.4.3 연결성(Linkage)의 개념
C/C++에서 모든 정의(Definition) 는 연결성을 가진다.
연결성이란, 변수나 함수가 다른 번역 단위(Translation Unit)에서도 참조될 수 있는지 여부를 나타내는 개념이다.

- 외부 연결성(External Linkage)  
정의된 번역 단위뿐만 아니라 다른 번역 단위에서도 사용 가능한 변수나 함수.
기본적으로 모든 전역 변수와 함수는 외부 연결성을 가진다.
extern 키워드를 사용하면 다른 .cpp 파일에서 참조 가능하다.
- 내부 연결성(Internal Linkage)  
정의된 번역 단위(파일) 내에서만 사용 가능한 변수나 함수.
static 키워드를 사용하면 내부 연결성을 갖는다.
다른 .cpp 파일에서도 동일한 이름의 변수를 정의해도 충돌하지 않는다.
클래스에서 private: 접근 지정자와 비슷한 개념으로 볼 수 있음.

- 중요한 개념
  - static이 붙은 변수나 함수는 해당 번역 단위(파일) 내에서만 사용 가능하다.
  - extern을 사용하면 다른 번역 단위에서 선언된 변수를 참조할 수 있다.
  - static이 붙은 함수는 해당 파일에서만 호출 가능하다.
  - 인라인 함수(inline function)의 경우, 헤더에서 정의될 때 기본적으로 내부 연결성을 가진다(static처럼 동작). 여러 .cpp 파일에서 포함되더라도, 각 번역 단위에서 별도의 함수 복사본이 생성되므로 충돌하지 않는다.


#### 3.3.5 C/C++ 프로그램의 메모리 구조
C/C++ 프로그램의 실행 파일은 메모리에 여러 세그먼트로 나뉘어 올라간다. 주요 세그먼트는 다음과 같다.

1. 텍스트 세그먼트 (Text Segment)
    - 코드 세그먼트라고도 불림.
프로그램의 모든 함수 기계어를 포함.
2. 데이터 세그먼트 (Data Segment)
    - 초기값이 있는 전역 및 정적 변수 저장.
실행 시 메모리에 배치되며, 지정된 초기값으로 설정됨.
3. BSS 세그먼트 (Block Started by Symbol)
    - 초기화되지 않은 전역 및 정적 변수 저장.
    - C/C++에서는 자동으로 0으로 초기화됨.
4. 읽기 전용 데이터 세그먼트 (Read-only Data Segment)
    - const 상수, 부동소수점 상수 등이 저장됨.
    - 기계어 코드 내 삽입되는 경우도 있음.


- 추가 개념  
전역 변수는 초기화 여부에 따라 데이터 세그먼트 또는 BSS 세그먼트에 저장됨.
static 키워드를 사용하면 정적 변수로서 특정 범위에서만 사용 가능하지만, 메모리 구조적으로는 전역 변수와 동일하게 취급됨.
함수 내부의 static 변수는 해당 함수가 처음 호출될 때 초기화됨.

##### 3.3.5.2 프로그램 스택

함수가 불릴 때마다 스택 메모리 안의 연속된 공간이 스택 위로 마련되며, 이것을 스택에 푸시한다고 말한다. 그리고 이런 메모리블록을 스택 프레임 이라고 한다. 스택 프레임에는 세 가지 종류의 데이터가 저장된다.
1. 리턴 주소  
2. CPU 레지스터  
3. 지역 변수

##### 3.3.5.3 동적 할당 힙

#### 3.3.6 멤버 변수

선언만으로는 메로리 할당이 이뤄지지 않는다. 정의가 되는 것들만 메모리 할당이 이루어진다.

#### 3.3.7 메모리상의 객체구조

데이터 구조를 선언할 때 미리 메모리 정렬과 패킹을 염두에 두는 것은 좋을 습관이다.

##### 3.3.7.2 C++ 클래스의 메모리 구조
C++에서는 상속과 가상 함수 때문에 C 구조체와 조금 다르다.
클래스나 베이스 클래스에 가상 함수가 있는경우 4바이트(대상 플랫폼이 64비트인 경우 8바이트)가 클래스 구조에 추가 되고, 대개 클래스의 제일 앞에 위치한다. 이 4혹은 8바이트는 vpointer라고 불린, 이는 vtable이라고 불리는 자료 구조를 가르키는 포인터가 있기 때문이다.

### 3.4 컴퓨터 하드웨어 기초  
언어가 고수준일수록 코드가 구동되는 하드웨어의 세부 사항으로부터 멀어진다. 하드웨어 구조에 대한 이해는 코드 최적화에 도움이 된다. 또한 병렬 프로그래밍에도 필수적이다.

#### 3.4.1 비교적 단순한 구세대 컴퓨터를 통해 배우기
구세대 컴퓨터는 단순한 CPU 구조를 가지고 있기 때문에 컴퓨터의 구조에 대해 이해하는데 많은 도움이 된다.  
- 마이클 애브라시의 Graphics Programming Black Book

#### 3.4.2 컴퓨터의 구조
컴퓨터 구조를 가장 단순하게 생각하면 중앙 처리 장치(CPU)와 여러 열(bank)의 메모리가 마더보드에 있고, 이 둘이 하나 이상의 버스를 통해 연결되며, I/O 포트 또는 확장 슬롯을 통해 외부 주변 장치와 연결되는 것이다.

#### 3.4.3 CPU
- 수리/논리 장치(ALU)
- 부동소수 장치(FPU)
- 벡터 처리 장치(VPU)
- 메모리 컨트롤러(MC) 또는 메모리 관리 장치(MMU) : 칩 내부 또는 외부의 메모리 장치와의 인터페이스를 처리한다.
- 레지스터 : 임시 저장소
- 제어 장치(CU) 

이 모든 것을 구동하는 것이 클럭이다. 클럭의 진동수에 따라 명령어를 처리하거나 계산을 하는 등의 CPU의 동작이 얼마나 빨리 수행되는지 결정된다.

##### 3.4.3.1 ALU

##### 3.4.3.2 VPU
오늘날의 CPU는 FPU가 없고 VPU가 이를 대체한다. 벡터 처리는 SIMD라고도 불리는데, 하나의 수리 연산자가 여러 짝의 입력에 동시에 수행되기 때문이다.

##### 3.4.3.3 레지스터
ALU나 FPU는 성능을 극대화하고자 레지스터라 불리는 특수 고성능 메모리에 있는 데이터만 처리하한다. 보통 빠르고 비싼멀티-초트 정적 RAN 또는 SRAM으로 구현한다.

##### 3.4.3.4 제어 장치
CPU가 컴퓨터의 뇌라면 제어 장치(CP)는 CPU의 뇌라 할 수 있다.

#### 3.4.4 클럭
CPU의 상태 변경은 보통 시스템 클럭이라 부르는 주기적 방형파를 통해 구동된다. 이 신호의 상승 및 하강 시점을 클럭 사이클이라 부르며, CPU는 사이클마다 최소한 하나의 기본 연산을 처리한다.  
반드시 한 클럭에 1개의 CPU 명령어를 처리할수 있는 것은 아니다. 오늘날의 파이프라인 구조 CPU들은 가장 단순한 명령어도 여러 개의 단계로 나눈다.

#### 3.4.5 메모리
ROM은 전원이 꺼져도 지워지지 않는 데이터.
SRAM와 DRAM으로 구분 할 수 있는데 DRAM은 주기적으로 내용을 갱신해 줘야 데이터가 지워지지 않는다.  
RAM은 그 외의 디자인 특성에 따라 구분하기도 하는데, 다음은 그중 일부다.
- 멀티포트 인지 여부, 동시에 여러 개의 CPU의 구성 요소가 접근 할 수 있는지 여부
- 클럭에 동기화로 동작하는지 또는 비동기화로 동작하는지로 구분
- 이중 데이터 레이트(DDR) 액세스, 즉 클럭의 상승 상태 변화와 하강 상태 변화에서 모두 RAM을 읽고 쓸 수 있는지 여부로 구분한다.

#### 3.4.6 버스
CPU와 메모리 사이에 데이터가 전달되는 연결을 버스라고 한다.  
컴퓨터에는 보통 두 가지 종류, 즉 주소 버스와 데이터 버스가 있다.

#### 3.4.6.2 워드
워드라는 용어는 보통 여러 바이트 값을 나타내는 데 쓰인다.

#### 3.4.7 기계어와 어셈블리어
CPU가 봤을 때 `프로그램`이라는 것은 비교적 단순한 명령어의 순차적인 흐름에 불과하다.

#### 3.4.7.1 명령어 집합 아키텍처
- ISA(Instruction Set Architecture): CPU가 지원하는 명령어 집합, 주소 모드, 메모리 내 명령어 형식 등을 포함하는 개념.

- ABI(Application Binary Interface): 소프트웨어 인터페이스와 관련, ISA와는 다른 개념.

- 명령어 유형:

  - 이동(Move): 레지스터 간 또는 메모리 간 데이터 이동.
  - 수리 연산(Arithmetic Operation): 덧셈, 뺄셈, 곱셈 등.
  - 비트와이즈 연산(Bitwise Operation): AND, OR, XOR 등.
  - 시프트/회전(Shift/Rotate): 비트 이동 연산.
  - 비교(Comparison): 두 값의 크기 비교.
  - 점프/분기(Jump/Branch): 프로그램 흐름 변경.
  - 푸시/팝(Push/Pop): 스택을 이용한 데이터 저장 및 복원.
  - 함수 호출/리턴(Function Call/Return): 함수 실행 및 종료.
  - 인터럽트(Interrupt): CPU가 특정 이벤트를 처리하도록 하는 메커니즘.
  - 기타: NOP(No-Operation) 같은 특수 명령어 포함.


#### 3.4.7.2 기계어

- 기계어(Machine Language)란?
  - 컴퓨터가 이해하는 명령어를 **숫자로 인코딩**한 것.
  - CPU/ISA마다 기계어 형식이 다름.

- 명령어 구성 요소
  1. **명령코드(Opcode)**: CPU가 수행할 동작 지정 (예: 덧셈, 이동, 점프 등).
  2. **피연산자(Operand)**: 명령어의 입력 및 출력 값.
  3. **옵션 필드**: 주소 모드 및 기타 플래그 지정.

- 피연산자 종류
  - 레지스터 이름 (예: `R0, R1`)
  - 숫자 리터럴 (예: `5, 0x10`)
  - 메모리 주소 (예: `0x102ED5C`)

- 명령어 인코딩 방식
  - **가변 길이 인코딩**: 명령어마다 차지하는 메모리 크기가 다름.
  - **고정 길이 인코딩**: 모든 명령어가 동일한 크기의 메모리를 사용.

-  명령어 워드 크기
   - 보통 **32비트 또는 64비트** 크기.
   - **VLIW (Very Long Instruction Word) CPU**: 여러 명령어를 하나의 워드에 넣어 병렬 실행 가능.

#### 3.4.7.3 어셈블리 언어  

- **어셈블리 언어(Assembly Language)란?**
  - 기계어보다 **기억하기 쉬운 문자 기반 언어**.
  - `opcode`를 사람이 읽기 쉬운 **줄임말(예: `ADD`, `MOV`)**로 표현.
  - **피연산자**를 이름으로 지정 가능 (예: `R0`, `EAX`).

- **어셈블리 프로그램 특징**
  - **라인 단위 구성**: 한 줄에 **한 개의 명령어** 포함.
  - 특정 메모리 위치에 **라벨(Label) 사용 가능**.
  - 점프/분기 명령어에서 **메모리 주소 대신 라벨 참조**.

- **어셈블러(Assembler)**
  - 어셈블리 코드를 **CPU가 이해하는 기계어로 변환하는 프로그램**.

- **C 코드와 어셈블리 코드 예제**
  - 아래 C 코드:
    ```c
    if (a > b)
        return a + b;
    else
        return 0;
    ```
  - 어셈블리 변환:
    ```assembly
    cmp eax, ebx      ; EAX와 EBX 비교
    jle ReturnZero    ; EAX <= EBX이면 ReturnZero로 점프
    add eax, ebx      ; EAX + EBX 수행 후 결과 저장
    ret               ; 반환 (EAX 값 반환)

    ReturnZero:
    xor eax, eax      ; EAX를 0으로 설정
    ret               ; 반환 (EAX 값 반환)
    ```
  - **코드 분석**
    - `cmp eax, ebx`: `EAX`와 `EBX` 비교.
    - `jle ReturnZero`: `EAX <= EBX`이면 `ReturnZero`로 이동.
    - `add eax, ebx`: 덧셈 연산 후 결과를 `EAX`에 저장.
    - `ret`: 반환 (`EAX` 값이 반환값 역할).
    - `xor eax, eax`: `EAX`를 0으로 설정하여 반환값을 0으로 만듦.

#### 3.4.7.4 주소 지정 방식

주소 지정 방식은 데이터를 **레지스터와 메모리 사이에서 이동**하는 다양한 방법을 정의.

- **레지스터 주소 지정**: 레지스터 간에 값 이동.
- **즉시 주소 지정**: 상수 값을 직접 명령어에 포함.
- **직접 주소 지정**: 특정 메모리 주소에서 값을 읽거나 씀.
- **레지스터 간접 주소 지정**: 메모리 주소를 레지스터가 가리키는 방식 (**포인터와 유사**).
- **상대 주소 지정**: 현재 위치 기준으로 상대적 주소를 계산 (**배열 인덱싱과 유사**).
- **기타 방식**: 특정 CPU에서만 지원하는 **특수한 주소 지정 방식 존재**.


## 3.5 메모리 구조

### 3.5.1 메모리 맵핑
주소 공간은 이론적으로 2^𝑛 바이트의 공간을 사용 가능 (n = 주소 버스 비트 수). 메모리장치는 연속된 주소 공간을나눠서 배정한다.
물리적 메모리 장치가 컴퓨터의 특정 주소 공간의 일부로 배정되면, 이 주소 공간이 메모리 장치에 맵핑됐다고 한다.

---

#### 3.5.1.1 메모리 맵 I/O

- **I/O 장치도 주소 공간에 매핑** 가능 (예: NIC, 조이패드 등)
- **Memory-Mapped I/O**:
  - 메모리처럼 접근하여 장치와 통신 (예: `0xC000~0xC0FF`)
  - 프로그램에서 읽고 쓰면 하드웨어 I/O로 동작
- **Port-Mapped I/O**:
  - 별도 포트 주소와 레지스터를 통해 접근
  - (예: 아두이노의 포트 I/O 제어)

---

#### 3.5.1.2 비디오 램

- **비디오 RAM (VRAM)**:
  - 디스플레이가 직접 접근하는 메모리 공간
  - 초기 디스플레이는 ASCII 코드 등을 읽어 화면 표시
- **IBM PC 등**에서는 VRAM을 CPU와 공유하거나, 별도로 위치
- **GPU 장착 PC**에서는 보통 VRAM은 GPU가 접근 가능하도록 비디오 카드에 위치

---

#### 3.5.1.3 케이스 스터디: 애플 II 메모리 맵

- **16비트 주소 버스 (64KiB 공간)** 내에서 다양한 장치 매핑
- 주소 공간 배치:
  ```
  0xC100~0xFFFF : ROM
  0xC000~0xC0FF : 메모리 맵 I/O
  0x0400~0xBFFF : 범용 RAM
  0x4000~0x5FFF : High-res video RAM (page 2)
  0x2000~0x3FFF : High-res video RAM (page 1)
  0x0800~0x1FFF : 범용 RAM
  0x0800~0x0BFF : Text/Lo-res video RAM (page 2)
  0x0400~0x07FF : Text/Lo-res video RAM (page 1)
  0x0200~0x03FF : 범용 및 특수용도 RAM
  0x0100~0x01FF : 프로그램 스택
  0x0000~0x00FF : Zero page (주로 DOS에서 사용)
  ```

- **특징**: 애플 II는 실제 물리적 메모리 칩에 직접 매핑되었음
- 현대 시스템은 **가상 주소(Virtual Address)** 기반 운영

---

#### 3.5.2 가상 메모리

- **가상 메모리**는 CPU가 참조하는 주소와 실제 메모리 주소가 다름
- **룩업 테이블**을 통해 가상 주소 → 물리 주소로 변환
- 장점:
  - **메모리 절약** (자주 안 쓰는 페이지는 디스크로)
  - **보안 강화** (프로세스 간 주소 공간 격리)

#### 3.5.2.1 가상 메모리 페이지

- 가상 메모리는 **페이지 단위(보통 4KiB)** 로 관리됨
- 예: 32비트 주소 → 4GiB / 4KiB = 약 104만 페이지

#### 3.5.2.2 가상 주소 → 물리 주소 변환

- 가상 주소 = **페이지 번호 + 오프셋**
- MMU가 페이지 테이블을 통해 물리 주소로 변환
- 예:  
  - 가상 주소: `0x1A7C6310`  
  - → 페이지 번호: `0x1A7C6`, 오프셋: `0x310`  
  - 매핑된 물리 페이지: `0x73BB9`  
  - → 최종 물리 주소: `0x73BB9310`

#### 3.5.2.3 페이지 폴트

- 물리 메모리에 없는 가상 주소 접근 시 **페이지 폴트** 발생
- 운영체제가 디스크에서 해당 페이지 로드
- 처리 불가능하면 프로그램 종료 + 코어 덤프

#### 3.5.2.4 변환 색인 버퍼 (TLB)

- **TLB (Translation Lookaside Buffer)**: 최근 페이지 매핑 정보를 저장하는 캐시
- MMU (Memory Management Unit,MMU는 메모리 관리 장치로, CPU와 실제 메모리(RAM) 사이에서 주소 변환을 담당하는 하드웨어 장치) 옆에 있어 접근 속도 빠름

#### 3.5.2.5 더 읽을거리

- [Virtual Memory Paging and Swapping](https://gabrieltolomei.wordpress.com/miscellanea/operating-systems/virtual-memory-paging-and-swapping)
- Ulrich Drepper - [What Every Programmer Should Know About Memory](https://www.akkadia.org/drepper/cpumemory.pdf)
"""

---

### 3.5.3 지연 감소를 위한 메모리 구조

메모리 접근 속도는 CPU 성능에 큰 영향을 미친다.  
**메모리 접근 지연 (memory access latency)** 은 CPU가 메모리에 요청을 보내고 실제 데이터를 받기까지 걸리는 시간이다.  
이 지연은 다음 세 가지 요인에 의해 영향을 받는다:

1. 개별 메모리 셀 구현 기술  
2. 메모리에서 지원하는 읽기/쓰기 포트 수  
3. 메모리 셀과 CPU 코어 간의 물리적 거리  

### 📌 메모리 종류별 지연 특성

- **SRAM**: 지연이 낮지만, 면적 크고 비용이 높음  
- **DRAM**: 지연은 크지만, 면적과 비용이 적음  
- **Multi-port RAM**: 동시에 여러 접근 가능 → 병목 완화  
- CPU와 메모리 간 거리도 지연에 영향 → 신호 이동 시간 때문

---

#### 3.5.3.1 메모리 갭 (Memory Gap)

초창기에는 CPU 명령 실행 속도와 메모리 접근 속도가 비슷했음.  
하지만 CPU 성능이 빠르게 향상되며 **메모리 접근 지연**이 큰 병목으로 작용.  
이 차이를 **메모리 갭**이라고 부르며, 해마다 격차가 커지고 있음.

> 📈 그림 3.24는 CPU와 메모리 성능 격차가 커지는 추세를 시각화한 그래프를 보여줌.

### 🛠 메모리 접근 지연 최소화 기법

1. 빠른 메모리를 CPU 코어 가까이 배치  
2. CPU가 다른 작업을 하도록 하여 메모리 접근 숨기기  
3. 데이터를 효율적으로 배치하여 접근 최소화  

---

#### 3.5.3.2 레지스터 파일 (Register File)

**레지스터 파일**은 접근 지연 최소화를 위한 가장 극단적인 메모리 구조임. CPU 안에 있는 초고속 메모리이다. 

- 보통 **SRAM 기반** 다중 포트를 사용하여 만들어진다.
- **CPU ALU 근처**에 위치 → 매우 빠른 접근 가능  
- 주소 변경, 캐시 일관성, 버스 통신 등을 거치지 않음  
- **crossbar switch** 없이 직접 연결됨

### 💡 레지스터 메모리가 비싼 이유

1. 가장 자주 사용되는 메모리  
2. RAM에 비해 크기가 매우 작아 고밀도 설계 필요

---
### 3.5.4 메모리 캐시 계층

CPU와 메모리 속도 차이를 극복하기 위해 **캐시 계층(memory cache hierarchy)** 구조 사용.  
작고 빠른 **L1 캐시**는 CPU 코어에 매우 가까워 접근 속도가 빠르다.  
**L2, L3 캐시**는 더 멀리 떨어져 있지만 용량이 크며, 자주 사용하는 데이터를 복사해 저장하여 접근 지연을 줄임.

---

#### 📌 캐시 접근 동작

- 프로그램이 자주 접근하는 데이터를 캐시에 저장
- 요청한 데이터가 캐시에 **있으면 → 캐시 히트(hit)**  
- 없으면 주메모리에서 가져오며, 이 경우 **캐시 미스(miss)** 발생 → 느림

---

### 3.5.4.1 캐시 라인

캐시는 데이터를 개별 바이트 단위가 아닌 캐시 라인(cache line)이라는 블록 단위로 저장함.

#### 🔁 지역성의 법칙(Locality of Reference)

1. **공간적 지역성**: 인접한 주소를 연속 접근하는 경향 (ex. 배열 순회)  
2. **시간적 지역성**: 최근 사용된 데이터를 곧 다시 사용하는 경향 (ex. 변수 재사용)

→ 캐시는 이 지역성을 활용해 성능 향상

---

### 3.5.4.2 캐시 라인과 주메모리 주소 매핑

- 캐시는 **작기 때문에** 주메모리보다 적은 주소만 저장 가능  
- **캐시 라인 수** = `캐시 크기 / 라인 크기`  
- 주메모리 블록들이 반복적으로 같은 캐시 라인에 매핑됨  
- 이를 위해 **주소를 태그(tag), 라인 번호, 오프셋**으로 나눔

---

### 3.5.4.3 캐시 주소 부여

- CPU가 메모리 주소를 요청하면 → 해당 주소를 캐시 주소로 변환  
- 캐시 컨트롤러는 라인 번호 확인 후 태그 비교  
- 일치하면 **히트**, 불일치하면 **미스**

---

### 3.5.4.4 집합 연관 및 교체 정책

- **직접 매핑 (Direct Mapped)**: 주메모리 블록 1개는 캐시 라인 1개에만 저장 가능  
- **집합 연관 (Set Associative)**: 한 주메모리 주소가 여러 캐시 라인 중 하나에 저장 가능  
  - 예: 2-웨이, 4-웨이 등  
- **교체 정책**:  
  - LRU (Least Recently Used)  
  - FIFO (First In First Out)  
  - Random 등

---

### 3.5.4.5 멀티레벨 캐시

- CPU는 보통 **L1, L2** 캐시를 사용하며, 고성능 시스템은 **L3, L4**까지 있음  
- L1 캐시는 작지만 가장 빠름 → 없으면 L2 확인 → 없으면 주메모리  
- **캐시 계층이 깊을수록** 성능 최적화가 중요

---

### 3.5.4.6 명령어 캐시와 데이터 캐시

- **I 캐시 (Instruction Cache)**: 실행할 명령어 저장  
- **D 캐시 (Data Cache)**: 실행 중 필요한 데이터 저장  
- 두 캐시는 보통 물리적으로 분리되어 동작  
- 코드를 최적화할 때 **I/D 캐시 성능 모두 고려** 필요

---

### 3.5.4.7 쓰기 정책

- **Write-through**: 캐시에 쓸 때 동시에 주메모리에도 씀  
- **Write-back**: 캐시에만 먼저 쓰고, 나중에 메모리에 반영  
- 성능과 안정성의 트레이드오프 존재

---

### 3.5.4.8 캐시 일관성: MESI, MOESI, MESIF

- 멀티코어 시스템에서 **캐시 간 데이터 불일치 방지** 필요  
- 대표 프로토콜:
  - **MESI**: Modified, Exclusive, Shared, Invalid  
  - **MOESI**, **MESIF** 등도 존재  
- 각 코어는 **공유 L2 캐시**를 통해 일관성을 유지

---

### 3.5.4.9 캐시 미스 피하기

- 캐시 미스는 불가피하지만, **최소화가 목표**  
- 전략:
  - 데이터 연속 배치 (공간적 지역성 활용)
  - 루프의 코드 크리를 가능ㅎ 한 작게 하고 가장 안쪽 루프에서 함수 호출을 피하는것이다. 만약 어쩔 수 없이 함수를 호출한다면 함수의 코드도 가능한 작게 해야 한다. 이렇게하면 전체 루프 코드가 캐시에 계속 남을 확률이 높아진다.
  - 인라인 함수를 신중하게 사용 - 작은 함수를 인라인화 하는 것은 성능 향상에 큰 도움을 준다. 그러면 인라인이 너무 커지면 코드 크기가 늘어나고 핵심 코드가 캐시에 안들어갈 수도 있다.

---

### 3.5.5 불균일 메모리 접근

멀티프로세서 기반 게임 콘솔/PC는 **UMA (Uniform Memory Access)** 와 **NUMA (Non-Uniform Memory Access)** 중 하나의 메모리 구조를 선택해야 함.

#### 🔸 UMA (균일 메모리 접근)

- 모든 CPU 코어가 **하나의 주메모리 뱅크**에 접근 가능.
- 모든 공간이 **동일한 물리 주소 공간**에 있음.
- 캐시 계층으로 접근 지역을 해결하는 방식.
- PS4는 UMA 구조로, 모든 코어가 주메모리 공유 → **클러스터 간 L2 캐시 공유**로 인한 경쟁 발생.

#### 🔸 NUMA (불균일 메모리 접근)

- 각 코어에 **전용 RAM인 로컬 스토어(Local Store)** 를 배정.
- 로컬 스토어는 **작고 빠르며, L1 캐시처럼 코어 근처**에 있음.
- 로컬 스토어는 **명시적 접근**이 필요하며, DMA를 통해 데이터 이동 가능.

---

### 3.5.5.1 PS3의 SPU 로컬 스토어

- PS3는 NUMA 구조 기반.
- 메인 CPU(PPU) 1개 + **SPU 6개**로 구성.
- SPU는 각각 **256KiB 로컬 스토어**를 가지며, **독립된 물리 주소 공간**을 사용.

#### 💡 접근 구조 요약

- PPU: 256MiB 시스템 RAM 접근.
- RSX GPU: 256MiB 비디오 RAM 접근.
- SPU는 자신 로컬 스토어만 접근 가능 → **다른 SPU/PPU/VRAM 직접 접근 불가**.
- **DMA Ring Bus**와 **DMA Controller**를 통해 SPU 간 혹은 SPU ↔ 주메모리 간 데이터 이동.

> 📊 그림 3.29: PS3 셀 브로드밴드 구조

---

### 3.5.5.2 PS2 스크래치패드

- PS2의 메인 CPU "EE(Emotion Engine)"는 **16KiB 스크래치패드 메모리**를 탑재.
- 이외에도 **16KiB 명령어 캐시(I$)**, **8KiB 데이터 캐시(D$)** 보유.
- **VU0/VU1 벡터 유닛** 2개, 각각 **L1 캐시** 탑재.
- 4MiB 비디오 램 + GPU(GS: Graphic Synthesizer) 포함.

#### 📌 스크래치패드 특징

- CPU 다이 내부에 있어 **L1 캐시 수준의 빠른 접근** 가능.
- **매핑된 메모리**로 캐시를 거치지 않고 접근함.
- EE와 VU 유닛이 동시에 접근 가능.
- DMA 요청 또는 C/C++의 `memcpy()`로 데이터 이동 가능.


---



