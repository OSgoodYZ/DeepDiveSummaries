# 4장 병렬성과 병행 프로그래밍

## 4.1 병행성과 병렬성에 대한 정의

### 4.1.1 병행성 (Concurrency)

- 하나의 문제를 해결하기 위해 여러 개의 제어 흐름을 활용.
- 제어 흐름:
  - 한 프로세스 내 여러 스레드(thread) 사용
  - 여러 컴퓨터에 분산된 프로세스
  - 파이버(fiber)나 코루틴(coroutine) 사용
- 병행 프로그래밍과 순차적 프로그래밍의 핵심 차이: **공유 데이터에 대한 접근**
- **독립적 데이터**를 처리하는 것은 병행성이 아님.

### 병행성의 문제
- 공유 데이터에 대한 일관성, 정확성 확보가 중요
- **데이터 경쟁 상태(race condition)** 발생 위험
- 병행성의 핵심은 데이터 경쟁을 **찾고 제거**하는 것

---

### 4.1.2 병렬성 (Parallelism)

- **둘 이상의 하드웨어가 동시에 작동**하는 상태
- 예: 하나의 병렬 컴퓨터 → 여러 작업 동시 수행
- 반대: 직렬(serial) 컴퓨터 → 한 번에 하나의 작업만

#### 과거:
- 1989년 이전 대부분의 소비자용 컴퓨터는 직렬 구조
  - Apple II, 6502 CPU, Intel 8086/80286/80386 등

#### 현재:
- 멀티코어 CPU (Intel Core i7, AMD Ryzen 등)
- 다양한 병렬 컴퓨팅 형태로 확장 가능
  - 예: CPU 내부 ALU 병렬 구성, 컴퓨터 클러스터(cluster) 등

---

#### 4.1.2.1 묵시적 병렬성과 명시적 병렬성

* 묵시적 병렬성 (Implicit Parallelism)

  - 하나의 명령어 스트림을 효율적으로 처리하기 위해 CPU 내부 구성 요소 사용
  - 명령어 수준 병렬성(ILP: Instruction Level Parallelism)
  - 예시:
    - 파이프라인(pipeline)
    - 슈퍼스칼라 아키텍처(superscalar architecture)
    - VLIW 아키텍처

* 명시적 병렬성 (Explicit Parallelism)
  - 둘 이상의 명령어 스트림을 처리
  - CPU/시스템에 중복된 하드웨어 사용
  - **병행 소프트웨어**를 효율적으로 처리하기 위한 하드웨어 설계

    - 예시:
      - 하이퍼스레드 CPU
      - 멀티코어 CPU
      - 멀티프로세서 컴퓨터
      - 컴퓨터 클러스터(cluster)
      - 그리드 컴퓨팅(grid computing)
      - 클라우드 컴퓨팅(cloud computing)

---

### 4.1.3 작업 병렬성과 데이터 병렬성

- 병렬성을 이해하는 또 다른 방법은 **작업의 종류**에 따라 나누는 것.
  
#### ● 작업 병렬성 (Task Parallelism)
- 이질적인 명령어들이 병렬적으로 여러 실행됨 → 작업 병렬성
- 예: 한 코어에서 애니메이션 계산, 다른 코어에서는 충돌 체크 수행

#### ● 데이터 병렬성 (Data Parallelism)
- 하나의 동일한 명령어가 여러 데이터를 병렬적으로 수행하는 것
- 예: 4개의 코어가 각각 250개의 스키닝 행렬 계산

> 대부분의 병렬 프로그램은 이 두 가지 병렬성을 혼합하여 사용

---

### 4.1.4 플린 분류 (Flynn's Taxonomy)

- 마이클 J. 플린이 제안한 병렬성의 분류 방식 (1996)
- 병렬성을 제어 흐름(명령어 스트림)과 데이터 스트림 수의 조합으로 4가지로 구분

#### ● SISD (Single Instruction, Single Data)
- 하나의 명령어 스트림이 하나의 데이터 스트림 처리
- 가장 기본적인 구조

#### ● MIMD (Multiple Instruction, Multiple Data)
- 여러 명령어 스트림이 여러 데이터 스트림 처리
- 대표적인 병렬 구조

#### ● SIMD (Single Instruction, Multiple Data)
- 하나의 명령어 스트림이 여러 데이터 스트림을 동시에 처리

#### ● MISD (Multiple Instruction, Single Data)
- 여러 명령어 스트림이 하나의 데이터 스트림을 처리
- 거의 사용되지 않으며, 예외적인 상황에만 사용됨 (예: 오류 복구, 핫 스페어 등)

---

#### 4.1.4.1 단일 데이터와 다중 데이터

- "데이터 스트림"은 단순한 숫자 배열이 아님 → 연산자 중심의 설명 필요
- 대부분 연산자는 2개의 입력을 받아 1개의 결과 출력

#### ● SISD
- 하나의 ALU가 곱 연산 후 나누기 연산 수행  
  `mul a, b` → `div c, d`

#### ● MIMD
- 2개의 ALU가 서로 독립적인 명령어 스트림을 병렬 수행  
  `ALU0: mul a, b`, `ALU1: sub g, h`

#### ● 시간 분할 MIMD
- 하나의 ALU가 시분할 방식으로 2개의 명령어 스트림을 처리

#### ● SIMD
- 벡터 처리 유닛(VPU)을 사용해 한 쌍의 4원소 벡터를 입력받아 연산

#### ● MISD
- 동일한 명령어 스트림을 두 ALU가 나눠 수행하여 **이론적으로 동일한 결과**를 출력
- 핫 스페어(hot spare)로 사용되기도 함

---

#### 4.1.4.2 GPU 병렬성: SIMT

- SIMT (Single Instruction Multiple Thread): GPU 설계에서 SIMD와 MIMD의 혼합 구조
- **멀티스레딩** 기법을 사용해 명령어 스트림을 시간 분할하여 병렬 처리
- 다양한 제조사들이 채택하는 디자인
- ‘매니코어(manycore)’라는 표현도 사용됨

---

### 4.1.5 병행성과 병렬성의 직교적 성질

- 병렬 하드웨어 없이도 병행 소프트웨어는 가능
- 병행성과 병렬성은 **서로 독립적 개념**이지만, 함께 쓰이면 성능 향상 가능

#### 예:
- 단일 스레드 CPU에서도 병행 소프트웨어 실행 가능 (멀티태스킹 등)
- 단일 명령어 수준 병렬성도 성능 향상 목적

---

### 4.1.6 4장의 로드맵

- 4.2절: 묵시적 병렬성에 대해 설명
- 4.3절: 명시적 병렬성의 형태 확인
- 이후 다양한 병렬 프로그래밍 기법을 살펴봄
- 마지막으로 SIMD 벡터 프로세싱과 GPU 병렬 프로그래밍(GPGPU) 적용 사례 분석

---

## 4.2 묵시적 병렬성

- 단일 스레드 실행 속도를 향상시키기 위한 **하드웨어 기반 병렬성 기법**
- CPU 제조사들이 코드 변경 없이 성능을 높이기 위해 채택
- 주요 기법:
  - **파이프라인 (Pipeline)**
  - **슈퍼스칼라 (Superscalar)**
  - **VLIW (Very Long Instruction Word)**

---

### 4.2.1 파이프라인 방식

- 명령어를 여러 단계로 나눠 **겹쳐서 병렬 실행**
- 주요 단계:
  - **인출(Fetch)**: 명령어를 메모리에서 읽음
  - **해석(Decode)**: 명령어 분석
  - **실행(Execute)**: ALU, FPU 등에서 연산 수행
  - **메모리 접근(Memory Access)**: 메모리 읽기/쓰기
  - **레지스터 기록(Write-back)**: 연산 결과를 저장
- 여러 명령어가 동시에 각기 다른 단계에서 실행됨

---

### 4.2.2 지연 시간과 처리량

- **지연 시간 (Latency)**: 명령어 하나가 끝나는 데 걸리는 시간  
  (T_pipeline = 각 단계 지연 시간의 합)

- **처리량 (Throughput)**: 단위 시간당 처리 가능한 명령어 수  
  (처리량 f = 가장 느린 단계의 시간의 역수)

---


### 4.2.3 파이프라인 깊이

- 각 단계의 **지연 시간 균형**이 중요
- 특정 단계가 느리면 전체 성능 저하
- **단계 수를 늘려** 짧은 단계로 분할하여 처리량 개선 가능
- 실제 CPU는 보통 **4~30단계** 사이의 파이프라인 구조를 가짐

---

### 4.2.4 정체 (Stall)

- 다음 명령어가 대기해야 하는 상태
- 파이프라인 단계 중 하나가 **비거나 지연**되면 전체 명령어 흐름이 멈춤
- "거품(bubble)", "딜레이 슬롯(delay slot)"으로도 표현

---


### 4.2.5 데이터 의존성

- 명령어 스트림 내에서 **명령어 간 의존성**으로 발생하는 정체
- 파이프라인의 다섯 단계를 거쳐야 다음 명령어가 실행될 수 있는 경우 발생
- 대표적 예시:
  ```asm
  mov ebx, 5
  imul eax, 10
  add eax, 7  ; imul의 결과가 있어야 add 실행 가능
  ```

---

### 데이터 의존성의 종류

- **데이터 의존성 (Data Dependency)**
- **제어 의존성 (Control Dependency)**
- **구조적 의존성 (Structural Dependency)**

---

#### 4.2.5.1 명령어 재배열

- 의존성 대기 시간 동안 **의존성 없는 명령어를 앞당겨 실행**
- 컴파일러가 자동으로 재배열하거나, 숙련된 프로그래머가 직접 가능
- 성능 개선에 큰 역할, 다중 스레드 레벨에서도 활용됨

---

#### 4.2.5.2 비순차적 명령어 실행 (Out-of-Order Execution)

- CPU가 실행 시점을 재조정하여 **의존성 없는 명령어를 먼저 실행**
- Look-ahead window로 미래 명령어를 탐색
- 정적인 재배열보다 더 강력한 **동적 스케줄링**

---

### 4.2.6 분기 의존성

- **조건 분기 명령어로 인해 발생하는 의존성**
- 분기 결과가 나와야 이후 명령어 실행 가능
- 예시:
  ```c
  return (b != 0) ? a / b : defaultVal;
  ```

---

#### 4.2.6.1 추측 실행 (Speculative Execution)

- 분기 결과를 **예측**하고, 예측된 분기에 따라 명령어 실행
- 예측 실패 시 다시 실행 (branch penalty 발생)
- 고급 CPU는 **분기 예측기** 포함

---

#### 4.2.6.2 프레디케이션 (Predication)

- 조건 분기에 따라 두 결과 중 하나 선택
- **비트 마스크 연산**으로 두 결과 중 하나를 선택
- 분기를 제거해 **분기 예측 실패 가능성 감소**

- 이를 마스크와 union을 사용해 실행 시 예외 없이 처리 가능
- PowerPC, PS3, SIMD 명령어 등에서 활용

### 4.2.7 슈퍼스칼라 CPU

- 기존 파이프라인 구조를 확장해 **한 사이클에 여러 명령어 실행 가능**
- CPU 내부에 각 파이프라인 단계를 담당하는 회로를 **2개 이상 배치**
- 명령어 스케줄러가 **비순차적 실행**과 **추측 실행**을 통해 성능 향상
- 데이터 의존성, 분기 의존성, 자원 의존성 문제 발생 가능

---

#### 4.2.7.1 디자인의 복잡도

- 단순 복붙 아님. 제어 로직이 매우 복잡
- 같은 연산 유닛 자원을 공유할 때 충돌 발생 가능 (자원 의존성)
- 명령어 분배를 위한 로직이 **스칼라 CPU보다 훨씬 복잡**

---

#### 4.2.7.2 슈퍼스칼라와 RISC

- 슈퍼스칼라는 보통 **RISC 기반**으로 설계
- 복잡한 명령 줄이고 트랜지스터 수 절약, 실행 효율 증가

---

### 4.2.8 VLIW (Very Long Instruction Word)

- **명령어 스케줄링을 컴파일러가** 수행 → 하드웨어 단순화
- **복잡한 분배 로직 불필요**, 대신 명령어를 병렬로 묶어서 실행
- CPU는 지정된 유닛에서 **병렬로 동시에 실행**
- 실행 유닛 활용률이 높음 (단, 트랜지스터 수 많아짐)

---

- **PS2, PS3 등 콘솔**에 실제 사용됨 (예: VU0, VU1 벡터 유닛)
- 명령어 묶음 단위로 명확하게 병렬 실행
- 단점: 하드웨어는 단순하지만 **컴파일러 설계는 어려움**

---

## 4.3 명시적 병렬성

- **병행 소프트웨어**를 더 효율적으로 실행하기 위한 구조
- 병렬 하드웨어가 여러 명령어 스트림을 동시에 실행할 수 있게 설계됨
- 단위 크기 기준으로 설명: 하이퍼스레딩 → 멀티코어 → 대칭/비대칭 멀티프로세싱 → 분산 컴퓨팅

---

### 4.3.1 하이퍼스레딩 (Hyper-Threading)

- 하나의 코어에서 **두 개의 스레드 실행** 가능
- 공유 자원(백엔드, L1 캐시)을 활용해 **유휴 슬롯 활용**
- 듀얼코어 대비 실행량은 적지만, 트랜지스터 소모는 작음

---

### 4.3.2 멀티코어 CPU

- 하나의 다이(die)에 **여러 개의 코어** 탑재
- 각 코어가 독립적으로 명령어 스트림 처리
- 다양한 구조와 혼합 가능: 파이프라인, 슈퍼스칼라, VLIW, 하이퍼스레딩 등

#### 콘솔 예시:
- **PS4**: AMD Jaguar 8코어 + Radeon GPU (8GiB GDDR5)
- **Xbox One**: AMD Jaguar 8코어 + Radeon GPU (8GiB GDDR3 + eSRAM)

---

### 4.3.3 대칭 vs 비대칭 멀티프로세싱

- **SMP (Symmetric MultiProcessing)**:
  - 모든 코어 동일, 운영체제가 균등하게 배분
  - 특정 스레드가 특정 코어에서 실행되도록 설정 가능

- **AMP (Asymmetric MultiProcessing)**:
  - 마스터 코어가 나머지를 제어
  - **PS3의 셀 프로세서**가 대표적 예시 (PPU + SPU)

---

### 4.3.4 분산 컴퓨팅

- 여러 독립된 컴퓨터들이 **협업하여 하나의 작업을 처리**
- 가장 넓은 의미의 병렬성
- 예시:
  - 컴퓨터 클러스터
  - 그리드 컴퓨팅
  - 클라우드 컴퓨팅

  ---

 ### 4.4 운영체제 기초

운영체제는 병렬 프로그래밍이 가능한 환경을 제공하는 소프트웨어 핵심 구성 요소.

---

### 4.4.1 커널

- 운영체제의 **핵심** 역할, 하드웨어와 직접 통신
- 키보드, 마우스 등 이벤트 처리 및 프로그램 스케줄링 담당
- 사용자 프로그램은 커널 위에서 실행됨

#### 커널 모드 vs 사용자 모드

- **커널 모드**: 특권 명령 실행 가능 (I/O, 메모리 접근 등)
- **사용자 모드**: 제한된 권한, 커널 호출 통해 로우레벨 서비스 사용
- 보호 고리(protection ring): 신뢰도에 따라 0~3 고리로 나뉨

#### 커널 모드 특권

- 커널 모드는 privileged instruction 사용 가능
- 메모리 보호, 레지스터 설정, 인터럽트 제어 등의 권한 보유

---

### 4.4.2 인터럽트

- CPU에게 **이벤트 발생 알림** (키보드 입력, 타이머 종료 등)
- 하드웨어/소프트웨어 인터럽트로 구분됨
- 인터럽트 서비스 루틴(ISR) 호출 → 현재 작업 중단하고 처리

---

### 4.4.3 커널 호출

- 사용자 프로그램이 커널 기능 요청 시 사용
- 시스템 호출(system call)이라고도 함
- 예: 메모리 매핑, 파일 입출력, 네트워크 접근 등

---

### 4.4.4 선점형 멀티태스킹

- 프로그램 간 **타임 슬라이스**로 CPU를 공유
- 초기에는 협력형(CPU 양보) 방식 → 후에 선점형 도입
- 프로그램이 강제로 중단될 수 있어 안정성 증가

---

### 4.4.5 프로세스

- 실행 중인 프로그램의 **인스턴스**
- 하나의 시스템에 여러 프로세스가 동시 구동 가능

#### 4.4.5.1 프로세스의 구성

- 프로세스 ID (PID)
- 사용자/그룹 권한
- 부모 프로세스 정보
- 가상 메모리 공간
- 환경 변수, 핸들, 작업 디렉터리
- 동기화 및 통신 자원
- **하나 이상의 스레드**

---

- 스레드는 명령어 스트림의 실행 단위
- 하나의 프로세스에 여러 스레드 포함 가능
- 커널은 스레드 단위로 스케줄링함


---

#### 4.4.5.2 프로세스의 가상 메모리 맵

- 프로세스는 물리 주소가 아닌 **가상 주소(virtual address)** 를 통해 메모리에 접근
- 운영체제는 **페이지 테이블**을 이용해 가상 주소를 물리 주소로 매핑
- 각 프로세스는 **고유한 가상 페이지 테이블**을 갖고 있어 독립적인 메모리 공간을 사용

---

### 프로세스의 메모리 맵 구성

- 텍스트, 데이터, BSS 섹션: 프로그램 실행 파일에서 읽혀온 데이터
- 공유 라이브러리(DLL, PRX 등) 관련 정보
- 각 스레드의 콜 스택
- `malloc()` 등으로 할당한 동적 메모리(힙)
- 메모리 맵트 파일 등으로 매핑된 파일 내용
- 접근 불가능한 커널 영역

---

### 텍스트, 데이터, BSS 섹션

- 프로세스 실행 시 커널이 생성한 가상 주소 맵에 매핑
- 텍스트, 데이터, BSS는 낮은 주소부터 연속적으로 배치됨

---

### 콜 스택

- 스레드마다 별도 존재
- 호출이 깊어질수록 **높은 주소에서 낮은 주소 방향**으로 쌓임

---

### 힙 영역

- `malloc()`, `new` 등 동적 메모리 할당에 사용
- 낮은 주소에서 높은 주소 방향으로 증가
- 할당 및 해제에 따라 조정됨

---

### 공유 라이브러리

- 처음 호출한 프로세스가 로드하면 해당 물리 메모리에 적재
- 이후 프로세스들은 이 메모리를 **가상 주소 공간에 매핑**만 수행
- 메모리 절약 및 실행 속도 향상
- 주의사항:
  - 라이브러리 업데이트 시 호환성 문제 발생 가능
  - 윈도우에서는 DLL 지옥 문제 발생 → **매니페스트 시스템**으로 해결

---

### 커널 페이지

- 사용자 공간과는 별도로 존재 (32비트 기준: 0x80000000 이상 영역)
- 사용자 프로세스는 접근 불가
- 시스템 호출 시 커널 모드로 전환하여 접근
- 최근에는 보안 이슈(Meltdown, Spectre 등)로 커널 공간 보호 강화

---

### 프로세스 메모리 맵 예시 (32비트 Windows)

- 텍스트, 데이터, BSS는 낮은 주소에 위치
- 힙은 그 위쪽, 콜 스택은 높은 주소부터 아래로 쌓임
- 공유 메모리는 힙과 스택 사이에 위치
- 커널 공간은 0x80000000 이상 주소부터 예약됨

---

### 4.4.6 스레드

- 스레드는 실행 중인 1개의 기계어 명령어 스트림을 내포
- 프로세스 내의 각 스레드는 다음과 같은 요소로 이루어짐:

  - **스레드 식별자(TID)**  
    프로세스 내에서 고유한 값이며, 운영체제 전체에서 고유하지 않을 수 있음

  - **콜 스택(Call Stack)**  
    현재 실행 중인 함수의 스택 프레임을 포함하는 연속된 메모리 블록

  - **레지스터**  
    명령어 스트림에서 현재 명령어를 가리키는 명령어 포인터(IP), 베이스 포인터(BP), 스택 포인터(SP) 등 포함

  - **스레드 로컬 저장소**  
    각 스레드마다 할당되는 범용 메모리

---

### 기본 개념

- 기본적으로 하나의 프로세스는 하나의 메인 스레드를 가지며, 보통 `main()` 함수부터 실행됨
- 최신 운영체제에서는 하나의 프로세스 안에 여러 개의 스레드 실행이 가능함 (concurrent)

---

### 스레드와 실행 문맥

- 스레드는 명령어 스트림을 실행하기 위한 최소한의 자원(스택 프레임, 레지스터 집합)을 제공
- 프로세스는 이러한 자원을 다수의 스레드에 할당
- 프로세스는 실행 문맥과 가상 메모리 공간을 공유하며, 스레드는 개별 실행 문맥을 가짐

---

#### 4.4.6.1 스레드 라이브러리

- 운영체제는 다중 스레드를 생성/조작하기 위한 다양한 **스레드 라이브러리**를 제공
- 대표적인 표준:
  - POSIX `pthread`
  - C11/C++11 `std::thread`
- 예: 소니 PlayStation SDK의 `sce` 계열 API는 POSIX 스레드와 유사함

---

### 스레드 API의 주요 기능

1. **생성**: 새 스레드를 만드는 함수 또는 클래스 생성자  
2. **종료**: 호출한 스레드를 종료  
3. **종료 요청**: 다른 스레드에게 종료 요청  
4. **휴면**: 일정 시간 동안 현재 스레드를 대기 상태로 전환  
5. **양보**: 현재 스레드의 실행 시간을 다른 스레드에 양보  
6. **결합**: 현재 스레드를 종료 상태로 전환하고, 다른 스레드의 종료를 기다림

---

#### 4.4.6.2 스레드 생성과 종료

- **시작**: 프로그램 실행 시 `main()` 함수에서 시작  
- **생성 함수 예시**:
  - POSIX: `pthread_create()`
  - Windows: `CreateThread()`
  - C++11: `std::thread`

---

### 스레드 종료 방식

- **자연스럽게 종료**: 시작 함수가 리턴될 때 자동으로 종료  
- **명시적 종료**: `pthread_exit()` 같은 함수를 사용하여 종료  
- **다른 스레드에 의해 종료**: 외부에서 강제로 취소 요청  
- **프로세스 종료에 따라 종료**: 프로세스 종료 시 소속된 모든 스레드 종료

---
p.270 차례