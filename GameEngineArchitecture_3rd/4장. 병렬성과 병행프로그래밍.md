# 4장 병렬성과 병행 프로그래밍

## 4.1 병행성과 병렬성에 대한 정의

### 4.1.1 병행성 (Concurrency)

- 하나의 문제를 해결하기 위해 여러 개의 제어 흐름을 활용.
- 제어 흐름:
  - 한 프로세스 내 여러 스레드(thread) 사용
  - 여러 컴퓨터에 분산된 프로세스
  - 파이버(fiber)나 코루틴(coroutine) 사용
- 병행 프로그래밍과 순차적 프로그래밍의 핵심 차이: **공유 데이터에 대한 접근**
- **독립적 데이터**를 처리하는 것은 병행성이 아님.

### 병행성의 문제
- 공유 데이터에 대한 일관성, 정확성 확보가 중요
- **데이터 경쟁 상태(race condition)** 발생 위험
- 병행성의 핵심은 데이터 경쟁을 **찾고 제거**하는 것

---

### 4.1.2 병렬성 (Parallelism)

- **둘 이상의 하드웨어가 동시에 작동**하는 상태
- 예: 하나의 병렬 컴퓨터 → 여러 작업 동시 수행
- 반대: 직렬(serial) 컴퓨터 → 한 번에 하나의 작업만

#### 과거:
- 1989년 이전 대부분의 소비자용 컴퓨터는 직렬 구조
  - Apple II, 6502 CPU, Intel 8086/80286/80386 등

#### 현재:
- 멀티코어 CPU (Intel Core i7, AMD Ryzen 등)
- 다양한 병렬 컴퓨팅 형태로 확장 가능
  - 예: CPU 내부 ALU 병렬 구성, 컴퓨터 클러스터(cluster) 등

---

#### 4.1.2.1 묵시적 병렬성과 명시적 병렬성

* 묵시적 병렬성 (Implicit Parallelism)

  - 하나의 명령어 스트림을 효율적으로 처리하기 위해 CPU 내부 구성 요소 사용
  - 명령어 수준 병렬성(ILP: Instruction Level Parallelism)
  - 예시:
    - 파이프라인(pipeline)
    - 슈퍼스칼라 아키텍처(superscalar architecture)
    - VLIW 아키텍처

* 명시적 병렬성 (Explicit Parallelism)
  - 둘 이상의 명령어 스트림을 처리
  - CPU/시스템에 중복된 하드웨어 사용
  - **병행 소프트웨어**를 효율적으로 처리하기 위한 하드웨어 설계

    - 예시:
      - 하이퍼스레드 CPU
      - 멀티코어 CPU
      - 멀티프로세서 컴퓨터
      - 컴퓨터 클러스터(cluster)
      - 그리드 컴퓨팅(grid computing)
      - 클라우드 컴퓨팅(cloud computing)

---

### 4.1.3 작업 병렬성과 데이터 병렬성

- 병렬성을 이해하는 또 다른 방법은 **작업의 종류**에 따라 나누는 것.
  
#### ● 작업 병렬성 (Task Parallelism)
- 이질적인 명령어들이 병렬적으로 여러 실행됨 → 작업 병렬성
- 예: 한 코어에서 애니메이션 계산, 다른 코어에서는 충돌 체크 수행

#### ● 데이터 병렬성 (Data Parallelism)
- 하나의 동일한 명령어가 여러 데이터를 병렬적으로 수행하는 것
- 예: 4개의 코어가 각각 250개의 스키닝 행렬 계산

> 대부분의 병렬 프로그램은 이 두 가지 병렬성을 혼합하여 사용

---

### 4.1.4 플린 분류 (Flynn's Taxonomy)

- 마이클 J. 플린이 제안한 병렬성의 분류 방식 (1996)
- 병렬성을 제어 흐름(명령어 스트림)과 데이터 스트림 수의 조합으로 4가지로 구분

#### ● SISD (Single Instruction, Single Data)
- 하나의 명령어 스트림이 하나의 데이터 스트림 처리
- 가장 기본적인 구조

#### ● MIMD (Multiple Instruction, Multiple Data)
- 여러 명령어 스트림이 여러 데이터 스트림 처리
- 대표적인 병렬 구조

#### ● SIMD (Single Instruction, Multiple Data)
- 하나의 명령어 스트림이 여러 데이터 스트림을 동시에 처리

#### ● MISD (Multiple Instruction, Single Data)
- 여러 명령어 스트림이 하나의 데이터 스트림을 처리
- 거의 사용되지 않으며, 예외적인 상황에만 사용됨 (예: 오류 복구, 핫 스페어 등)

---

#### 4.1.4.1 단일 데이터와 다중 데이터

- "데이터 스트림"은 단순한 숫자 배열이 아님 → 연산자 중심의 설명 필요
- 대부분 연산자는 2개의 입력을 받아 1개의 결과 출력

#### ● SISD
- 하나의 ALU가 곱 연산 후 나누기 연산 수행  
  `mul a, b` → `div c, d`

#### ● MIMD
- 2개의 ALU가 서로 독립적인 명령어 스트림을 병렬 수행  
  `ALU0: mul a, b`, `ALU1: sub g, h`

#### ● 시간 분할 MIMD
- 하나의 ALU가 시분할 방식으로 2개의 명령어 스트림을 처리

#### ● SIMD
- 벡터 처리 유닛(VPU)을 사용해 한 쌍의 4원소 벡터를 입력받아 연산

#### ● MISD
- 동일한 명령어 스트림을 두 ALU가 나눠 수행하여 **이론적으로 동일한 결과**를 출력
- 핫 스페어(hot spare)로 사용되기도 함

---

#### 4.1.4.2 GPU 병렬성: SIMT

- SIMT (Single Instruction Multiple Thread): GPU 설계에서 SIMD와 MIMD의 혼합 구조
- **멀티스레딩** 기법을 사용해 명령어 스트림을 시간 분할하여 병렬 처리
- 다양한 제조사들이 채택하는 디자인
- ‘매니코어(manycore)’라는 표현도 사용됨

---

### 4.1.5 병행성과 병렬성의 직교적 성질

- 병렬 하드웨어 없이도 병행 소프트웨어는 가능
- 병행성과 병렬성은 **서로 독립적 개념**이지만, 함께 쓰이면 성능 향상 가능

#### 예:
- 단일 스레드 CPU에서도 병행 소프트웨어 실행 가능 (멀티태스킹 등)
- 단일 명령어 수준 병렬성도 성능 향상 목적

---

### 4.1.6 4장의 로드맵

- 4.2절: 묵시적 병렬성에 대해 설명
- 4.3절: 명시적 병렬성의 형태 확인
- 이후 다양한 병렬 프로그래밍 기법을 살펴봄
- 마지막으로 SIMD 벡터 프로세싱과 GPU 병렬 프로그래밍(GPGPU) 적용 사례 분석

---

## 4.2 묵시적 병렬성

- 단일 스레드 실행 속도를 향상시키기 위한 **하드웨어 기반 병렬성 기법**
- CPU 제조사들이 코드 변경 없이 성능을 높이기 위해 채택
- 주요 기법:
  - **파이프라인 (Pipeline)**
  - **슈퍼스칼라 (Superscalar)**
  - **VLIW (Very Long Instruction Word)**

---

### 4.2.1 파이프라인 방식

- 명령어를 여러 단계로 나눠 **겹쳐서 병렬 실행**
- 주요 단계:
  - **인출(Fetch)**: 명령어를 메모리에서 읽음
  - **해석(Decode)**: 명령어 분석
  - **실행(Execute)**: ALU, FPU 등에서 연산 수행
  - **메모리 접근(Memory Access)**: 메모리 읽기/쓰기
  - **레지스터 기록(Write-back)**: 연산 결과를 저장
- 여러 명령어가 동시에 각기 다른 단계에서 실행됨

---

### 4.2.2 지연 시간과 처리량

- **지연 시간 (Latency)**: 명령어 하나가 끝나는 데 걸리는 시간  
  (T_pipeline = 각 단계 지연 시간의 합)

- **처리량 (Throughput)**: 단위 시간당 처리 가능한 명령어 수  
  (처리량 f = 가장 느린 단계의 시간의 역수)

---


### 4.2.3 파이프라인 깊이

- 각 단계의 **지연 시간 균형**이 중요
- 특정 단계가 느리면 전체 성능 저하
- **단계 수를 늘려** 짧은 단계로 분할하여 처리량 개선 가능
- 실제 CPU는 보통 **4~30단계** 사이의 파이프라인 구조를 가짐

---

### 4.2.4 정체 (Stall)

- 다음 명령어가 대기해야 하는 상태
- 파이프라인 단계 중 하나가 **비거나 지연**되면 전체 명령어 흐름이 멈춤
- "거품(bubble)", "딜레이 슬롯(delay slot)"으로도 표현

---


### 4.2.5 데이터 의존성

- 명령어 스트림 내에서 **명령어 간 의존성**으로 발생하는 정체
- 파이프라인의 다섯 단계를 거쳐야 다음 명령어가 실행될 수 있는 경우 발생
- 대표적 예시:
  ```asm
  mov ebx, 5
  imul eax, 10
  add eax, 7  ; imul의 결과가 있어야 add 실행 가능
  ```

---

### 데이터 의존성의 종류

- **데이터 의존성 (Data Dependency)**
- **제어 의존성 (Control Dependency)**
- **구조적 의존성 (Structural Dependency)**

---

#### 4.2.5.1 명령어 재배열

- 의존성 대기 시간 동안 **의존성 없는 명령어를 앞당겨 실행**
- 컴파일러가 자동으로 재배열하거나, 숙련된 프로그래머가 직접 가능
- 성능 개선에 큰 역할, 다중 스레드 레벨에서도 활용됨

---

#### 4.2.5.2 비순차적 명령어 실행 (Out-of-Order Execution)

- CPU가 실행 시점을 재조정하여 **의존성 없는 명령어를 먼저 실행**
- Look-ahead window로 미래 명령어를 탐색
- 정적인 재배열보다 더 강력한 **동적 스케줄링**

---

### 4.2.6 분기 의존성

- **조건 분기 명령어로 인해 발생하는 의존성**
- 분기 결과가 나와야 이후 명령어 실행 가능
- 예시:
  ```c
  return (b != 0) ? a / b : defaultVal;
  ```

---

#### 4.2.6.1 추측 실행 (Speculative Execution)

- 분기 결과를 **예측**하고, 예측된 분기에 따라 명령어 실행
- 예측 실패 시 다시 실행 (branch penalty 발생)
- 고급 CPU는 **분기 예측기** 포함

---

#### 4.2.6.2 프레디케이션 (Predication)

- 조건 분기에 따라 두 결과 중 하나 선택
- **비트 마스크 연산**으로 두 결과 중 하나를 선택
- 분기를 제거해 **분기 예측 실패 가능성 감소**

- 이를 마스크와 union을 사용해 실행 시 예외 없이 처리 가능
- PowerPC, PS3, SIMD 명령어 등에서 활용

### 4.2.7 슈퍼스칼라 CPU

- 기존 파이프라인 구조를 확장해 **한 사이클에 여러 명령어 실행 가능**
- CPU 내부에 각 파이프라인 단계를 담당하는 회로를 **2개 이상 배치**
- 명령어 스케줄러가 **비순차적 실행**과 **추측 실행**을 통해 성능 향상
- 데이터 의존성, 분기 의존성, 자원 의존성 문제 발생 가능

---

#### 4.2.7.1 디자인의 복잡도

- 단순 복붙 아님. 제어 로직이 매우 복잡
- 같은 연산 유닛 자원을 공유할 때 충돌 발생 가능 (자원 의존성)
- 명령어 분배를 위한 로직이 **스칼라 CPU보다 훨씬 복잡**

---

#### 4.2.7.2 슈퍼스칼라와 RISC

- 슈퍼스칼라는 보통 **RISC 기반**으로 설계
- 복잡한 명령 줄이고 트랜지스터 수 절약, 실행 효율 증가

---

### 4.2.8 VLIW (Very Long Instruction Word)

- **명령어 스케줄링을 컴파일러가** 수행 → 하드웨어 단순화
- **복잡한 분배 로직 불필요**, 대신 명령어를 병렬로 묶어서 실행
- CPU는 지정된 유닛에서 **병렬로 동시에 실행**
- 실행 유닛 활용률이 높음 (단, 트랜지스터 수 많아짐)

---

- **PS2, PS3 등 콘솔**에 실제 사용됨 (예: VU0, VU1 벡터 유닛)
- 명령어 묶음 단위로 명확하게 병렬 실행
- 단점: 하드웨어는 단순하지만 **컴파일러 설계는 어려움**

---

## 4.3 명시적 병렬성

- **병행 소프트웨어**를 더 효율적으로 실행하기 위한 구조
- 병렬 하드웨어가 여러 명령어 스트림을 동시에 실행할 수 있게 설계됨
- 단위 크기 기준으로 설명: 하이퍼스레딩 → 멀티코어 → 대칭/비대칭 멀티프로세싱 → 분산 컴퓨팅

---

### 4.3.1 하이퍼스레딩 (Hyper-Threading)

- 하나의 코어에서 **두 개의 스레드 실행** 가능
- 공유 자원(백엔드, L1 캐시)을 활용해 **유휴 슬롯 활용**
- 듀얼코어 대비 실행량은 적지만, 트랜지스터 소모는 작음

---

### 4.3.2 멀티코어 CPU

- 하나의 다이(die)에 **여러 개의 코어** 탑재
- 각 코어가 독립적으로 명령어 스트림 처리
- 다양한 구조와 혼합 가능: 파이프라인, 슈퍼스칼라, VLIW, 하이퍼스레딩 등

#### 콘솔 예시:
- **PS4**: AMD Jaguar 8코어 + Radeon GPU (8GiB GDDR5)
- **Xbox One**: AMD Jaguar 8코어 + Radeon GPU (8GiB GDDR3 + eSRAM)

---

### 4.3.3 대칭 vs 비대칭 멀티프로세싱

- **SMP (Symmetric MultiProcessing)**:
  - 모든 코어 동일, 운영체제가 균등하게 배분
  - 특정 스레드가 특정 코어에서 실행되도록 설정 가능

- **AMP (Asymmetric MultiProcessing)**:
  - 마스터 코어가 나머지를 제어
  - **PS3의 셀 프로세서**가 대표적 예시 (PPU + SPU)

---

### 4.3.4 분산 컴퓨팅

- 여러 독립된 컴퓨터들이 **협업하여 하나의 작업을 처리**
- 가장 넓은 의미의 병렬성
- 예시:
  - 컴퓨터 클러스터
  - 그리드 컴퓨팅
  - 클라우드 컴퓨팅

  ---

 ### 4.4 운영체제 기초

운영체제는 병렬 프로그래밍이 가능한 환경을 제공하는 소프트웨어 핵심 구성 요소.

---

### 4.4.1 커널

- 운영체제의 **핵심** 역할, 하드웨어와 직접 통신
- 키보드, 마우스 등 이벤트 처리 및 프로그램 스케줄링 담당
- 사용자 프로그램은 커널 위에서 실행됨

#### 커널 모드 vs 사용자 모드

- **커널 모드**: 특권 명령 실행 가능 (I/O, 메모리 접근 등)
- **사용자 모드**: 제한된 권한, 커널 호출 통해 로우레벨 서비스 사용
- 보호 고리(protection ring): 신뢰도에 따라 0~3 고리로 나뉨

#### 커널 모드 특권

- 커널 모드는 privileged instruction 사용 가능
- 메모리 보호, 레지스터 설정, 인터럽트 제어 등의 권한 보유

---

### 4.4.2 인터럽트

- CPU에게 **이벤트 발생 알림** (키보드 입력, 타이머 종료 등)
- 하드웨어/소프트웨어 인터럽트로 구분됨
- 인터럽트 서비스 루틴(ISR) 호출 → 현재 작업 중단하고 처리

---

### 4.4.3 커널 호출

- 사용자 프로그램이 커널 기능 요청 시 사용
- 시스템 호출(system call)이라고도 함
- 예: 메모리 매핑, 파일 입출력, 네트워크 접근 등

---

### 4.4.4 선점형 멀티태스킹

- 프로그램 간 **타임 슬라이스**로 CPU를 공유
- 초기에는 협력형(CPU 양보) 방식 → 후에 선점형 도입
- 프로그램이 강제로 중단될 수 있어 안정성 증가

---

### 4.4.5 프로세스

- 실행 중인 프로그램의 **인스턴스**
- 하나의 시스템에 여러 프로세스가 동시 구동 가능

#### 4.4.5.1 프로세스의 구성

- 프로세스 ID (PID)
- 사용자/그룹 권한
- 부모 프로세스 정보
- 가상 메모리 공간
- 환경 변수, 핸들, 작업 디렉터리
- 동기화 및 통신 자원
- **하나 이상의 스레드**

---

- 스레드는 명령어 스트림의 실행 단위
- 하나의 프로세스에 여러 스레드 포함 가능
- 커널은 스레드 단위로 스케줄링함


---

#### 4.4.5.2 프로세스의 가상 메모리 맵

- 프로세스는 물리 주소가 아닌 **가상 주소(virtual address)** 를 통해 메모리에 접근
- 운영체제는 **페이지 테이블**을 이용해 가상 주소를 물리 주소로 매핑
- 각 프로세스는 **고유한 가상 페이지 테이블**을 갖고 있어 독립적인 메모리 공간을 사용

---

### 프로세스의 메모리 맵 구성

- 텍스트, 데이터, BSS 섹션: 프로그램 실행 파일에서 읽혀온 데이터
- 공유 라이브러리(DLL, PRX 등) 관련 정보
- 각 스레드의 콜 스택
- `malloc()` 등으로 할당한 동적 메모리(힙)
- 메모리 맵트 파일 등으로 매핑된 파일 내용
- 접근 불가능한 커널 영역

---

### 텍스트, 데이터, BSS 섹션

- 프로세스 실행 시 커널이 생성한 가상 주소 맵에 매핑
- 텍스트, 데이터, BSS는 낮은 주소부터 연속적으로 배치됨

---

### 콜 스택

- 스레드마다 별도 존재
- 호출이 깊어질수록 **높은 주소에서 낮은 주소 방향**으로 쌓임

---

### 힙 영역

- `malloc()`, `new` 등 동적 메모리 할당에 사용
- 낮은 주소에서 높은 주소 방향으로 증가
- 할당 및 해제에 따라 조정됨

---

### 공유 라이브러리

- 처음 호출한 프로세스가 로드하면 해당 물리 메모리에 적재
- 이후 프로세스들은 이 메모리를 **가상 주소 공간에 매핑**만 수행
- 메모리 절약 및 실행 속도 향상
- 주의사항:
  - 라이브러리 업데이트 시 호환성 문제 발생 가능
  - 윈도우에서는 DLL 지옥 문제 발생 → **매니페스트 시스템**으로 해결

---

### 커널 페이지

- 사용자 공간과는 별도로 존재 (32비트 기준: 0x80000000 이상 영역)
- 사용자 프로세스는 접근 불가
- 시스템 호출 시 커널 모드로 전환하여 접근
- 최근에는 보안 이슈(Meltdown, Spectre 등)로 커널 공간 보호 강화

---

### 프로세스 메모리 맵 예시 (32비트 Windows)

- 텍스트, 데이터, BSS는 낮은 주소에 위치
- 힙은 그 위쪽, 콜 스택은 높은 주소부터 아래로 쌓임
- 공유 메모리는 힙과 스택 사이에 위치
- 커널 공간은 0x80000000 이상 주소부터 예약됨

---

### 4.4.6 스레드

- 스레드는 실행 중인 1개의 기계어 명령어 스트림을 내포
- 프로세스 내의 각 스레드는 다음과 같은 요소로 이루어짐:

  - **스레드 식별자(TID)**  
    프로세스 내에서 고유한 값이며, 운영체제 전체에서 고유하지 않을 수 있음

  - **콜 스택(Call Stack)**  
    현재 실행 중인 함수의 스택 프레임을 포함하는 연속된 메모리 블록

  - **레지스터**  
    명령어 스트림에서 현재 명령어를 가리키는 명령어 포인터(IP), 베이스 포인터(BP), 스택 포인터(SP) 등 포함

  - **스레드 로컬 저장소**  
    각 스레드마다 할당되는 범용 메모리

---

### 기본 개념

- 기본적으로 하나의 프로세스는 하나의 메인 스레드를 가지며, 보통 `main()` 함수부터 실행됨
- 최신 운영체제에서는 하나의 프로세스 안에 여러 개의 스레드 실행이 가능함 (concurrent)

---

### 스레드와 실행 문맥

- 스레드는 명령어 스트림을 실행하기 위한 최소한의 자원(스택 프레임, 레지스터 집합)을 제공
- 프로세스는 이러한 자원을 다수의 스레드에 할당
- 프로세스는 실행 문맥과 가상 메모리 공간을 공유하며, 스레드는 개별 실행 문맥을 가짐

---

#### 4.4.6.1 스레드 라이브러리

- 운영체제는 다중 스레드를 생성/조작하기 위한 다양한 **스레드 라이브러리**를 제공
- 대표적인 표준:
  - POSIX `pthread`
  - C11/C++11 `std::thread`
- 예: 소니 PlayStation SDK의 `sce` 계열 API는 POSIX 스레드와 유사함

---

### 스레드 API의 주요 기능

1. **생성**: 새 스레드를 만드는 함수 또는 클래스 생성자  
2. **종료**: 호출한 스레드를 종료  
3. **종료 요청**: 다른 스레드에게 종료 요청  
4. **휴면**: 일정 시간 동안 현재 스레드를 대기 상태로 전환  
5. **양보**: 현재 스레드의 실행 시간을 다른 스레드에 양보  
6. **결합**: 현재 스레드를 종료 상태로 전환하고, 다른 스레드의 종료를 기다림

---

#### 4.4.6.2 스레드 생성과 종료

- **시작**: 프로그램 실행 시 `main()` 함수에서 시작  
- **생성 함수 예시**:
  - POSIX: `pthread_create()`
  - Windows: `CreateThread()`
  - C++11: `std::thread`

---

### 스레드 종료 방식

- **자연스럽게 종료**: 시작 함수가 리턴될 때 자동으로 종료  
- **명시적 종료**: `pthread_exit()` 같은 함수를 사용하여 종료  
- **다른 스레드에 의해 종료**: 외부에서 강제로 취소 요청  
- **프로세스 종료에 따라 종료**: 프로세스 종료 시 소속된 모든 스레드 종료

---
### 4.4.6.3 스레드 결합

- **여러 자식 스레드를 생성해 계산 작업을 병렬 수행**하고, 이후 메인 스레드에서 결과를 확인하는 상황 예시.
- 예: 1000개의 계산을 4개 스레드로 분할 처리.

```c
ComputationResult g_aResult[1000];

void Compute(void* arg)
{
    uintptr_t startIndex = (uintptr_t)arg;
    uintptr_t endIndex = startIndex + 250;
    for (uintptr_t i = startIndex; i < endIndex; ++i)
    {
        g_aResult[i] = ComputeOneResult(...);
    }
}

void main()
{
    pthread_t tid[4];
    for (int i = 0; i < 4; ++i)
    {
        const uintptr_t startIndex = i * 250;
        pthread_create(&tid[i], nullptr, Compute, (void*)startIndex);
    }

    // 다른 작업 수행...

    // 모든 스레드가 종료될 때까지 기다림
    for (int i = 0; i < 4; ++i)
    {
        pthread_join(&tid[i], nullptr);
    }

    // 체크섬 계산
    unsigned checksum = Sha1(g_aResult, 1000 * sizeof(ComputationResult));
}
```

---

### 4.4.6.4 폴링, 블로킹, 양보

스레드가 어떤 **미래의 조건을 기다릴 때** 사용할 수 있는 3가지 방식:

1. **폴링 (Polling)**  
2. **블로킹 (Blocking)**  
3. **양보 (Yielding)**

---

#### 1. 폴링 (Polling)

- 특정 조건이 충족될 때까지 **짧은 루프 반복**
- 예: `while (!CheckCondition()) { /* 대기 */ }`
- 장점: 단순 구현  
- 단점: CPU 자원을 지속 소모  
- 이 방식은 `spin-wait`, `busy-wait` 라고도 부름

```c
while (!CheckCondition())
{
    // 바쁨-대기 상태로 루프 반복
}
```

---

#### 2. 블로킹 (Blocking)

- 조건이 충족될 때까지 **스레드를 수면(sleep) 상태로 전환**
- CPU 자원을 낭비하지 않음
- 스레드가 블로킹되는 대표적 경우:

  - **파일 열기**: `fopen()` 등
  - **명시적 수면**: `usleep()`, `Sleep()`, `std::this_thread::sleep_until()`
  - **스레드 결합**: `pthread_join()`
  - **뮤텍스 락 대기**: `pthread_mutex_wait()` 등

---

#### 3. 양보 (Yield)

- 폴링 루프 도중 **타임 슬라이스를 포기**
- 조건이 충족될 때까지 `pthread_yield()` 등으로 CPU를 다른 스레드에 넘김

```c
while (!CheckCondition())
{
    // 타임 슬라이스 양보
    pthread_yield(nullptr);
}
```

- `Sleep(0)`, `SwitchToThread()`(Windows), `_mm_pause()`(Intel) 등도 유사 기능

```c
while (!CheckCondition())
{
    // SSE2 전용: CPU 전력 소모 줄이고 대기
    _mm_pause();
}
```

---

### 참고 자료

- https://software.intel.com/en-us/comment/1134767  
- http://software.intel.com/en-us/forums/topic/309231  

### 4.4.6.5 문맥 교환 (Context Switch)

커널이 관리하는 모든 스레드는 다음의 세 상태 중 하나에 있음:

- **실행 중인 상태**: 스레드가 코어에서 실행 중
- **실행 가능한 상태**: 실행 가능하지만 슬라이스(CPU는 한 번에 하나의 쓰레드만 실행할 수 있다. 이때 커널은 각 쓰레드에게 번갈아가면서 CPU를 이용할 시간을 준다 이것을 타임 슬라이스라고한다.)를 기다리는 상태
- **블로킹된 상태**: 수면 상태이며, 조건을 기다리는 중

**문맥 교환**은 커널이 스레드의 상태를 바꿀 때 발생하며, 다음 상황에서 일어남:

- 인터럽트 도중 커널 진입
- 실행 중인 스레드가 명시적으로 커널 호출
- 특정 조건 충족으로 수면 상태의 스레드가 '깨움' 상태로

**스레드의 실행 문맥 (execution context)**:

- 명령어 포인터(IP), 스택 포인터(SP), 베이스 포인터(BP)
- 레지스터(GPR), 함수 호출 스택, 로컬 변수 등 포함

실행 중 → 실행 가능/블로킹 상태 전환 시 **레지스터 상태 저장**  
실행 가능 → 실행 중 전환 시 **레지스터 상태 복원**

**콜 스택**은 가상 메모리 내에 이미 존재하므로 별도 저장 불필요  
단, 프로세스 간 교환 시에는 가상 메모리 맵 등의 정보도 교체해야 함

---

### 4.4.6.6 스레드 우선순위와 선호도

스레드의 **우선순위(priority)** 와 **선호도(affinity)** 는 커널의 스케줄링 방식에 영향을 줌

#### 우선순위 (Priority)

- 높은 우선순위 → 낮은 우선순위보다 먼저 스케줄
- Windows: 6개 클래스 × 7개 레벨 → 총 42개 우선순위

**기본 원칙**:  
우선순위 높은 실행 가능 스레드가 있을 경우  
→ 낮은 우선순위 스레드는 스케줄되지 않음

> starvation(기아 상태) 방지 위해 스케줄러에 외부 정책 도입 가능

#### 선호도 (Affinity)

- 스레드를 특정 코어에 묶거나 선호 요청
- CPU 캐시 친화도 등의 이유로 설정

---

### 4.4.6.7 스레드 로컬 저장소 (Thread Local Storage, TLS)

- 프로세스의 모든 스레드는 자원(메모리)을 공유  
- 단, **TLS는 각 스레드에 독립적 메모리 공간 제공**

#### 예시

- 각 스레드마다 전용 힙 할당자 사용 가능
- TLS는 스레드 실행 문맥의 일부로 동작

#### 구현 방식

- TLS 블록은 프로세스의 모든 스레드가 접근 가능  
- 운영체제는 스레드마다 **자신만의 TLS 블록 주소를 보유**

---

### 4.4.6.8 스레드 디버깅

현대 디버거는 **멀티스레드 디버깅 도구**를 제공함

- 예: **Visual Studio의 스레드 창**
  - 모든 스레드 리스트 확인 가능
  - 각 스레드 클릭 시 실행 문맥 활성화
  - **콜 스택 추적** 및 **로컬 변수 조회**

해당 기능은 실행 가능, 블로킹 상태에서도 작동

---
## 4.4.7 파이버 (Fiber)

### 개념

- 커널 스케줄링이 아닌, 사용자 수준 협력적 멀티태스킹
- 일반적인 스레드는 커널이 스케줄링하지만, 파이버는 **명시적으로 제어**
- **잡(jobs)** 을 효율적으로 처리하고 싶을 때 사용됨 (게임 엔진 등에서 유용)
- 일부 OS에서 지원되며, **Windows**, **PlayStation SDK** 등에서 사용 가능

---

### 4.4.7.1 파이버 생성과 파괴

#### 변환과 생성

- 모든 프로세스는 기본적으로 **1개의 스레드**로 시작됨
- `ConvertThreadToFiber()`로 기존 스레드를 파이버로 변환
- `CreateFiber()`로 새로운 파이버 생성, 시작 주소를 인자로 받음

#### 실행과 파괴

- `SwitchToFiber()`로 파이버 간 전환
- 더 이상 필요 없는 파이버는 `DeleteFiber()`로 제거

---

### 4.4.7.2 파이버 상태

#### 두 가지 상태

- **활성화(active)**: CPU 코어에서 실행 중
- **비활성화(inactive)**: 대기 상태, CPU 리소스를 사용하지 않음

#### 상태 전환

- `SwitchToFiber()` 호출로 현재 파이버는 비활성화, 대상 파이버는 활성화됨
- **오직 해당 방식으로만 상태 전환 가능**

#### 유의점

- 파이버는 **블로킹 상태가 될 수 없음**
- 조건 기다릴 땐 `SwitchToFiber()`를 통해 직접 **양보해야 함**

---

### 4.4.7.3 파이버 이동

- 파이버는 **스레드 간 이동도 가능**
- 예: F 스레드의 파이버 D → G로 전환, 이후 H 파이버가 B 스레드로 이동
- 단, 파이버 간 이동은 **비활성 상태일 때만 가능**

---

### 4.4.7.4 파이버 디버깅

- 파이버는 OS 기능이므로 디버깅 도구에서 **스레드처럼 추적 가능**
- 예: **Visual Studio + SN Systems 디버거(PS4 디버깅용)**
- **콜 스택 추적**, **변수 보기**, **호출 스택 탐색** 등 가능

#### 실전 팁

- 타겟 플랫폼이 파이버 디버깅을 **지원하는지 사전 조사 필요**
- 디버깅 지원 없으면 **도입 장벽** 상승

---

### 4.4.7.5 참고 링크

- [MSDN 문서 링크](https://msdn.microsoft.com/en-us/library/windows/desktop/ms682661(v=vs.85).aspx)

---

p 280 차례